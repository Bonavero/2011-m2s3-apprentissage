\documentclass[french,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[frenchb]{babel}
\usepackage{hyperref}
\hypersetup{%
  colorlinks,%
  citecolor=black,%
  filecolor=black,%
  linkcolor=black,%
  urlcolor=black%
}

\usepackage{amsmath}
\DeclareMathOperator{\Pa}{Pa}
\DeclareMathOperator{\argmax}{argmax}

\title{Rapport\\Ordering-Based Search: A Simple and Effective Algorithm for Learning Bayesian Networks}
\author{BONAVERO Yoann \and DUPÉRON Georges}

\begin{document}

\maketitle
%\newpage

% Lien qui peut être utile : 
% http://asi.insa-rouen.fr/enseignants/~pleray/RB2003/2-ApprentissageStructure.pdf

\section{Résumé de l’article :}
\subsection{Quel est le problème étudié dans l’article ?}

Le problème consiste en l'apprentissage de structures de réseaux
Bayesiens à partir des données.

Dans un problème d'apprentissage, on cherche à prédire des variables
en fonction des valeurs d'autres variables. Il y a une relation de
causalité entre certaines variables~: la présence d'une certaine
valeur dans l'une modifie la distribution de probabilité des valeurs
dans l'autre.

Un réseau bayésien est un graphe dirigé où les nœuds sont des
«variables aléatoires» (généralement des quantités observables ou des
variables intermédiaires qui sont des sortes d'hypothèses
réutilisables par d'autres variables), où les arcs représentent la
dépendance de la variable d'arrivée par rapport à la variable de
départ, et où chaque nœud possède une fonction de probabilité
permettant de déterminer la probabilité de ses valeurs en fonction des
probabilités de ses entrées.

L'apprentissage de la structure d'un réseau bayésien (quelles
variables sont reliées à quelles autres) à partir de données mesurées
au préalable permet d'éviter la nécessité d'avoir des experts capable
de renseigner le système sur la causalité entre les différentes
variables. Ce problème est cependant NP-complet, et son espace de
recherche très grand (le nombre de structures possibles pour un
réseaux à $n$ nœuds est exponentiel). Les solutions sont donc des
recherches heuristiques de la meilleure structure.

\subsection{Quels sont les travaux relatifs au problème ? }
Chickering, en 1996 puis 2003 a établi que le problème de trouver la
structure de réseau optimale d'un réseau bayésien était un problème
NP-complet.

D'autres chercheurs ont établi que trouver la structure de réseau
optimale d'un réseau bayésien, avec un ordre donné sur les variables,
n'était pas NP-complet. De plus, si l'on limite à $k$ le nombre d'arcs
entrant pour chaque variable, la complexité est $O(n^k)$ avec $n$ le
nombre de variables.

Plusieurs algorithmes existent pour effectuer une recherche
heuristique de la structure de réseau optimale~:
\begin{itemize}
\item Recherche locale en utilisant un algorithme gourmand, avec des
  «listes Tabou» qui permettent d'éviter de défaire les modifications
  que l'on vient juste d'appliquer à la structure, et donc de revenir
  en arrière. C'est l'algorithme de base que peu d'autres algorithmes
  arrivent à améliorer de manière significative.
\item Un algorithme génétique portant sur les structures des réseaux.
\item Markov Chain Monte Carlo sur l'ordre des variables.
% TODO Yoann : tu sors ça d'où ? \item Restriction de l'espaces des arbres.
% TODO Yoann : tu sors ça d'où ? \item Wawelet-based search (à vérifier à plutôt l'air d'être un outil utilisé combiné avec une autre technique).
\item OR-search (Optimal Reinsertion). En 2003, Moore et Wong ont
  proposé un opérateur de modification de la structure (voir
  ci-dessous), qui permet à la recherche locale d'être plus efficace.
\item Ordering-based search (Méthode utilisée ici).
\item D'autres algorithmes ont été proposés, mais sont soit très
  compliqués à implémenter, soit n'apportent pas d'amélioration réelle
  à l'algorithme de base de recherche locale.
\end{itemize}

La plupart de ces algorithmes effectuent une recherche locale, et
lorsqu'ils atteignent un minimum local, redémarrent avec une autre
structure ou un autre ordre de départ.

Le principe de ces recherches locales est de partir d'une structure
(ou d'un ordre) donnée, et de la modifier avec des opérateurs (par
exemple ajouter un arc entre $A$ et $B$), et sélectionner parmi les
modifications possibles celle qui améliore le plus la fonction de
score.

\subsection{Quel est le paradigme adopté ?}
Comme beaucoup de problèmes en informatique, celui-ci peut se
simplifier en utilisant un niveau d'indirection.

Plutôt que de chercher la meilleure solution dans l'espace des
structures de réseaux, cet article prend en compte qu'il est
relativement facile de trouver la meilleure structure pour un ordre de
variables donné, avec la condition que le degré entrant des variables
soit borné.

La solution proposée est donc d'effectuer une recherche locale dans
l'espace des ordres des variables, qui est beaucoup plus petit
($2^{O(n \log n}$) que l'espace des structures de réseaux ($2^{\Omega(n^2)}$).

\subsection{Quels sont les principaux résultats obtenus ?}

Les auteurs de l'article ont comparé leurs résultats avec ceux obtenus
par une version optimisée de l'algorithme de base, et ceux obtenus par
l'algorithme OR-search.

Ils ont trouvé que Oredering-Based search prennait beaucoup de temps
de préparation, mais qu'ensuite la convergeance était
quasi-instantanée.

Lorsque le problème est simple (peu de variables et beaucoup
d'exemples desquels apprendre), l'algorithme de base (recherche locale
gourmande et listes de Tabou) et Ordering-Based search trouvent les
mêmes résultats. Cependant, lorsque le problème devient plus complexe,
Ordering-Based search trouve de meilleurs structures de réseau.

N'ayant pas la même machine pour effectuer les benchmark, et n'ayant
pas utilisé les mêmes mesures (temps CPU contre temps d'exécution
réel), les auteurs de l'article n'ont pas pu comparer correctement
Ordering-Based search avec OR-search, cependant les performances sont
suffisemment différentes pour pouvoir affirmer qu'Ordering-Based
search est plus efficace qu'OR-search.

\section{Apprentissage Bayesien :}
\subsection{Décrire le fonctionnement de l'apprentissage Bayésien}
l'apprentissage bayésiens consiste à déterminer la meilleure structure
pour décrire un ensemble de données définies.
L'apprentissage, la recherche de cette structure se base une comparaison
de l'ensembles des structures possible pour un ensemble de données.
La fonction fonction de scoring est par exemple un outil qui permet de
choisir plutôt une stucture qu'une autre. Il existe d'autre méthodes qui
permettent du comparer les structures entres elles afin d'améliorer la recherche.

\subsection{Que signifie la fonction de scoring ?}
La fonction de "scoring" est une fonction permettant de "noter", d'évaluer
 chaques structure selon diverses critères critères. cette notation va permettre
 de comparer celles-ci entre elles.
La fonction de scoring se doit donc d'être à la fois rapide, mais aussi d'être
localement décomposable afin de traiter des sous graphes..

\section{L'algorithme de recherche}
\subsection{Décrire l'espace de recherche utilisant les ordres}
L'espace de recherche est l'ensemble des ordres sur les variables du
réseau.

Pour passer d'un état (un ordre) à un autre dans la recherche locale,
l'opérateur utilisé est la permutation de deux variables adjacentes.

Pour un ordre sur $n$ variables, il y a donc $n-1$ ordres suivants
possibles en appliquant cet opérateur.

\subsection{Recherche dans cet espace}

$U_{i,\prec}$ est l'ensemble des ensembles de de variables précédant
$X_i$ dans l'ordre $\prec$, de cardinal inférieur ou égal à $k$.

$\Pa_\prec(X_i)$ est l'ensemble de parents optimal pour la variable
$X_i$, défini comme étant l'ensemble de variables précédant $X_i$ dans
$\prec$ et de cardinal inférieur ou égal à $k$, $\mathbf{U} \in
U_{i,\prec}$, maximisant le $score(X_i, U)$.

Le cardinal de $U_{i,\prec}$ pour une variable $X_i$ donnée est le
nombre de combinaisons de moins de $k$ éléments pris dans les $i-1$
variables précédentes. Le cardinal maximal est donc celui de
$U_{n,\prec}$, et vaut $\binom{n}{k}$.

Le meilleur réseau $G^*_\prec$ consistant avec un ordre $\prec$ est le
graphe dont l'ensemble des arcs entrant dans chaque nœud est le
meilleur ensemble de parents compatible avec cet ordre, soit
$\Pa_\prec(X_i)$.

Le meilleur réseau est le réseau $G^*_{\prec^*}$ c'est à dire le
meilleur réseau pour l'ordre $\prec*$. $\prec*$ est l'ordre pour
lequel «le meilleur réseau pour cet ordre» sera le meilleur, autrement
dit $\argmax_{\prec} score(G^*_\prec)$.

\subsection{Décrire la recherche, le caching et le pruning}

\subsubsection{Caching}

Lorsqu'on passe d'un ordre à un autre, l'ensemble $U_{i,prec}$ des
ensembles de variables précédant une variable $X_i$ reste le même,
sauf pour les deux variables permutées. En effet, si on permute $X_a$
et $X_b$, avec $a + 1 = b$, et soit $a' < a$ et $b' > b$, alors
l'ensemble des variables précédant $X_{a'}$ avant permutation reste le
même après permutation, vu qu'on n'a pas inséré ni enlevé de variables
dans l'intervalle $\{X_1, \dots, X_{a'-1}\}$, et l'ensemble des
variables précédent $X_{b'}$ avant permutation reste le même après
permutation, car $\{X_1, \dots, X_{a}, X_{b}, \dots, X_{b'-1}\}$ est
devenu $\{X_1, \dots, X_{b}, X_{a}, \dots, X_{b'-1}\}$~: $X_a$ et
$X_b$ ont été échangées, mais les variables présentes dans
l'intervalle $\{X_1, \dots, X_{b'-1}\}$ n'a pas changé.

Il est donc possible de conserver («mettre en cache») l'ensemble de
parents optimal $\Pa_\prec(X_i)$ pour les variables $X_i, i \neq a
\wedge i \neq b$ d'un état à l'autre, et il faut recalculer seulement
$\Pa_\prec(X_a)$ et $\Pa_\prec(X_b)$.

Lorsqu'on considère quelle est la meilleure permutation à effectuer,
pour passer de l'état $\prec$ à l'état $\prec'$ on calcule pour chaque
$\prec'$ la différence entre $score(G^*_\prec)$ (l'ancien score) et
$score(G^*_{\prec'})$ (le nouveau score).

L'application de la permutation des variables $X_a$ et $X_b$ ne
modifie la différence de score entre $\prec'$ et les états $\prec''$
obtenus en appliquant une permutation sur $\prec'$, sauf si la
nouvelle permutation porte sur les variables $X_a$ et $X_b$, car
l'ensemble $\Pa_\prec(X_i)$ n'a pas été modifié pour les variables
autres que $X_a$ et $X_b$, comme vu ci-dessus, et la fonction de score
est décomposable en la somme du score de chaque ensemble de
parents. Autrement dit, les permutations sur $\prec'$ qui ne portent
pas sur $X_a$ ou $X_b$ auront le même impact que lorsqu'on les
considérait sur $\prec$.

Pour recalculer les différences de score sur les permutations
possibles après la permutation de $X_a$ et $X_b$ (avec $a + 1 = b$),
on procède donc de la manière suivante~:
\begin{itemize}
\item Permuation $X_i,X_j$ avec $j < a$ et $i+1=j$~: la différence de
  score n'a pas changé.
\item Permuation $X_i,X_j$ avec $j = a$ et $i+1=j$~: Il faut calculer
  le nouveau score $score(G^*_{\prec'})$.
\item Permuation $X_i,X_j$ avec $i = a$ et $j = b$ et $i+1=j$~: Cela
  équivaut à «défaire» la permutation qu'on vient juste d'appliquer,
  soit transformer $\prec'$ en $\prec''=\prec$. La différence de score
  $score(G^*_{\prec'' = \prec}-G^*_{\prec'}$ est donc l'opposée de la
  différence de score $score(G^*_{\prec'}-G^*_{\prec}$.
\item Permuation $X_i,X_j$ avec $i = b$ et $i+1=j$~: Il faut calculer
  le nouveau score $score(G^*_{\prec'})$.
\item Permuation $X_i,X_j$ avec $i > b$ et $i+1=j$~: la différence de
  score n'a pas changé.
\end{itemize}
Cela signifie qu'à chaque étape, il y a au plus deux scores à
recalculer.

\subsubsection{Pruning}

Lorsqu'on considère les ensembles de parents possibles pour une
variable $X_i$, si on prend deux ensembles $\mathbf{U}' \subset
\mathbf{U}$, alors si $score(X_i, \mathbf{U}) \leq score(X_i,
\mathbf{U'})$, on peut éliminer $\mathbf{U}$ de toutes les recherches
futures, puisqu'à chaque fois que $\mathbf{U}$ sera un ensemble de
parents possibles pour $X_i$, $\mathbf{U}'$ sera aussi un ensemble de
parents possible, et préférable (car de meilleur score), puisqu'il est
inclus dans $\mathbf{U}$, donc respectera tout autant l'ordre $\prec$,
et il est plus petit, donc $|\mathbf{U}| \leq k \Rightarrow
|\mathbf{U}'| < k$.

Il est possible d'éliminer plus d'ensembles de parents possibles en
n'autorisant comme parents de $X_i$ que les variables qui sont en
forte corrélation avec $X_i$. Cela permet d'accélérer la recherche du
meilleur ensemble de parents, cependant il est possible que cela
élimine l'ensemble de parents faisant partie de la solution optimale,
donc avec cette modification, même en essayant tous les ordres sur les
variables, on n'a pas la garantie de trouver la meilleure structure de
réseau.

\section{Commentaires :}
\subsection{Quels sont les avantages et inconvénients de la méthode proposée (analyse détaillée demandée) ?}
\subsection{Est-il possible d'améliorer cette méthode pour apprendre des réseaux Bayésiens dont la tree-width est bornée ?}
\subsection{Est-il possible d'apprendre plus efficacement des réseaux Bayésiens dont la structure est un arbre dirigé (ou une forêt) ?}

\end{document}
